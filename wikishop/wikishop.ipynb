{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные и посмотрим на них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/toxic_comments.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таблица содержит тексты на английском языке и информацию о том, являются ли эти тексты токсичными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Варианты значений столбца toxic: [0 1]\n",
      "Количество положительных объектов: 10%\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "print('Варианты значений столбца toxic:', df['toxic'].unique())\n",
    "print('Количество положительных объектов: {:.0%}'.format(df['toxic'].mean()))\n",
    "print()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропущенных значений, ошибок в целевом признаке или проблем с типами в талице нет. Данные несбалансированные: положительных объектов только 10%.\n",
    "\n",
    "Очистим текст от лишних символов: оставим только символы английского алфавита. После этого проведём лемматизацию английского текста. Стоп-слова оставим в их исходном виде, чтобы учесть при создании векторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english', ignore_stopwords=True)\n",
    "\n",
    "def only_text(text, stemmer=stemmer):\n",
    "    '''\n",
    "    Оставляет в тексте только слова, написанные латиницей.\n",
    "    Лемматизирует английский текст.\n",
    "    '''\n",
    "    \n",
    "    clean_text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    clean_text = ' '.join([stemmer.stem(word) for word in clean_text.split()])\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.9 s, sys: 50.1 ms, total: 51.9 s\n",
      "Wall time: 51.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df['lemm_text'] = list(map(lambda x: only_text(x), df['text'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на несколько примеров текстов до и после преобразования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Geez, are you forgetful!  We've already discussed why Marx  was  not an anarchist, i.e. he wanted to use a State to mold his 'socialist man.'  Ergo, he is a statist - the opposite of an  anarchist.  I know a guy who says that, when he gets old and his teeth fall out, he'll quit eating meat.  Would you call him a vegetarian?\"\n",
      " 'Carioca RFA \\n\\nThanks for your support on my request for adminship.\\n\\nThe final outcome was (31/4/1), so I am now an administrator. If you have any comments or concerns on my actions as an administrator, please let me know. Thank you!'\n",
      " '\"\\n\\n Birthday \\n\\nNo worries, It\\'s what I do ;)Enjoy ur day|talk|e \"']\n"
     ]
    }
   ],
   "source": [
    "print(df['text'].sample(n=3, random_state=42).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['geez are you forget we ve alreadi discuss why marx was not an anarchist i e he want to use a state to mold his socialist man ergo he is a statist the opposit of an anarchist i know a guy who say that when he get old and his teeth fall out he ll quit eat meat would you call him a vegetarian'\n",
      " 'carioca rfa thank for your support on my request for adminship the final outcom was so i am now an administr if you have any comment or concern on my action as an administr pleas let me know thank you'\n",
      " 'birthday no worri it s what i do enjoy ur day talk e']\n"
     ]
    }
   ],
   "source": [
    "print(df['lemm_text'].sample(n=3, random_state=42).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При кросс-валидации обучающая выборка каждый раз меняется, поэтому для каждой итерации нужно заново использовать трансформер, создающий векторы из слов. Добавим TfidfVectorizer в пайплайн. Для создания векторов будем использовать важность слов и биграмм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def get_pipline(model, stop_words=stop_words):\n",
    "    '''\n",
    "    Создаёт пайплайн: считает оценки важности слов в лемматизированных текстах, \n",
    "    передаёт получившиеся векторы модели.\n",
    "    '''\n",
    "    pipeline = Pipeline(steps=[('count_tf_idf', TfidfVectorizer(stop_words=stop_words, ngram_range=(1,2))),\n",
    "                               ('model', model)])\n",
    "        \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим функцию, которая будет находить лучшие параметры для модели и считать F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_params(model, params, X, y):\n",
    "    '''Ищет лучшие параметры модели с помощью GridSearch. Возвращает лучшие параметры и F1.'''\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    grid_search = GridSearchCV(\n",
    "        model, params, \n",
    "        scoring = 'f1', \n",
    "        cv = kf,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    print('Лучшие параметры:', grid_search.best_params_)\n",
    "    print('F1 = {:.3f}'.format(grid_search.best_score_))\n",
    "    print()\n",
    "    return grid_search.best_estimator_, grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "Данные загружены и изучены. Тексты написаны на английском языке, присутствует дисбаланс классов.\n",
    "\n",
    "Все тексты очищены от лишних символов и лемматизированы. Написана функция для создания паплайна: 1) преобразование текстов в векторы с использованием важности слов и биграмм, 2) модель машинного обучения. Стоп-слова не учитываются. Также написана функция для поиска лучших гиперпараметров на кросс-валидации и расчёта метрики F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для ориентира посмотрим, какое значение метрики можно получить на dummy-модели. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'model__strategy': 'stratified'}\n",
      "F1 = 0.097\n",
      "\n",
      "CPU times: user 14.8 s, sys: 816 ms, total: 15.7 s\n",
      "Wall time: 43.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_dm = DummyClassifier(random_state=42)\n",
    "params_dm = {'model__strategy': ['stratified', 'most_frequent']}\n",
    "pipeline_dm = get_pipline(model_dm)\n",
    "pipeline_dm, f1_dm = search_params(pipeline_dm, params_dm, df['lemm_text'], df['toxic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим логистическую регрессию. Т.к. классы несбалансированы, попробуем вариант class_weight='balanced'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'model__C': 3, 'model__class_weight': None, 'model__penalty': 'l1'}\n",
      "F1 = 0.798\n",
      "\n",
      "CPU times: user 24.6 s, sys: 5.06 s, total: 29.6 s\n",
      "Wall time: 22min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_lr = LogisticRegression(random_state=42, solver='liblinear')\n",
    "\n",
    "params_lr = {\n",
    "    'model__penalty': ['l1', 'l2'],\n",
    "    'model__C': [1, 3],\n",
    "    'model__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "pipeline_lr = get_pipline(model_lr)\n",
    "pipeline_lr, f1_lr = search_params(pipeline_lr, params_lr, df['lemm_text'], df['toxic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшее значение F1 получено без учёта дисбаланса, т.е. при class_weight=None. \n",
    "\n",
    "Рассмотрим градиентный бустинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'model__max_depth': 10, 'model__n_estimators': 1500}\n",
      "F1 = 0.789\n",
      "\n",
      "CPU times: user 50min 2s, sys: 38 s, total: 50min 40s\n",
      "Wall time: 29min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_gb = LGBMClassifier(random_state=42)\n",
    "\n",
    "params_gb = {\n",
    "    'model__n_estimators': [1000, 1500],\n",
    "    'model__max_depth': [10, 5]\n",
    "}\n",
    "\n",
    "pipeline_gb = get_pipline(model_gb)\n",
    "pipeline_gb, f1_gb = search_params(pipeline_gb, params_gb, df['lemm_text'], df['toxic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У бустинга значение F1 получилось меньше, но оно тоже превышает заданную планку в 0.75.\n",
    "\n",
    "**Вывод**\n",
    "\n",
    "Для ориентира и оценки адекватности посчитано значение F1 для dummy-модели. Рассмотрены логистическая регрессия и градиентный бустинг с разным количеством гиперпараметров. Лучшие варианты обеих моделей показали значение F1 больше 0.75 и существенно превзошли dummy-модель. Наибольшее значение метрики у логистической регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В работе использован набор объектов: текст на английском языке и метка класса: 1 или 0 - токсичный текст или нет. Положительных объектов 10%. Все тексты очищены от лишних символов, лемматизированы и преобразованы в векторы по значению важности слов и биграмм без учёта стоп-слов. \n",
    "\n",
    "Рассмотрены модели логистической регрессии и градиентного бустинга. На кросс-валидации выбраны лучшие гиперпараметры и посчитано значение F1. Кроме того, значение метрики посчитано для dummy-модели. Логистическая регрессия показала лучшие результаты. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model     F1\n",
       "0     DummyClassifier  0.097\n",
       "1  LogisticRegression  0.798\n",
       "2      LGBMClassifier  0.789"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'model': ['DummyClassifier', 'LogisticRegression', 'LGBMClassifier'],\n",
    "    'F1': ['{:.3f}'.format(f1_dm), '{:.3f}'.format(f1_lr), '{:.3f}'.format(f1_gb)]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
